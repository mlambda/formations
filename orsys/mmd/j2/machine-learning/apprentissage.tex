\begin{frame}
  \frametitle{Apprentissage de modèles}
  Entrainement supervisé d'un modèle — overfit
  \imgtw{fit}
  \red{Problème : trop minimiser la perte n'est pas bon !}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage de modèles}
  \imgtw[.6]{learning-curve}
  → Minimiser la perte sur un ensemble de validation
\end{frame}

\begin{frame}
  \frametitle{Apprentissage de modèles}
  Séparation des données :
  \begin{itemize}
  \item ensemble d'entrainement
  \item ensemble de validation pour mesurer la généralisation
  \item ensemble de test (pour éviter le biais statistique)
  \end{itemize}
  → Split 60/20/20 habituel.
\end{frame}

\begin{frame}
  \frametitle{Apprentissage de modèles}
  Idéalement : Cross Validation
  Pour \og perdre\fg{} moins de données et mieux tester la
  généralisation, cross-validation :
  \imgtw[.9]{cv}
  Ici, 4-fold cross-validation.
\end{frame}

