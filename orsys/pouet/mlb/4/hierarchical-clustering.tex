\documentclass{formation}
\title{Machine Learning, méthodes et solutions}
\subtitle{Clustering Hiérarchique}

\begin{document}

\maketitle

\begin{frame}
  \frametitle{Clustering Hiérarchique}
  Deux approches :
  \begin{itemize}
  \item Agglomérantes (bottom-up)
  \item Divisantes (top-down)
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Classification Ascendante Hiérarchique (CAH)}
  Métode Agglomérante
  \begin{itemize}
  \item Chaque élément est dans une classe distincte
  \item On itère jusqu'à ce qu'on ait le nombre de classes voulues
  \item On utilise une mesure de dissimilarité inter-classe comme critère d'aggrégation
  \end{itemize}
  A chaque itération, on calcule la dissimilarité entre toutes les classes puis on fusionne les plus similaires.
\end{frame}

\begin{frame}
  \frametitle{Classification Ascendante Hiérarchique (CAH)}
  Quelques distances de dissimilarités, après avoir défini une distance D dans l'espace :
  \begin{itemize}
  \item saut minimum : $dissim(C_1,C_2) = \underset{x \in C_1,y \in C_2}{\min}{D(x,y)}$
  \item saut maximum : $dissim(C_1,C_2) = \underset{x \in C_1,y \in C_2}{\max}{D(x,y)}$
  \item saut moyen : $dissim(C_1,C_2) = \underset{x \in C_1,y \in C_2}{moyenne\;}{D(x,y)}$
  \item distance de Ward qui vise à maximiser l'inertie inter-classe
  \item ...
  \end{itemize}
  $O(n^2)$ < complexité < $O(n^3)$ !
\end{frame}

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
