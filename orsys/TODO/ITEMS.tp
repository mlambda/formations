Slides pour Travaux Pratiques

1) Introduction à la modélisation
- Introduction au langage Python.
- Introduction au logiciel Jupiter Notebook.
x- Les étapes de construction d'un modèle.
x- Les algorithmes supervisés et non supervisés.
x- Le choix entre la régression et la classification.
Travaux pratiques
- Installation de Python 3, d'Anaconda et de Jupiter Notebook.

2) Procédures d'évaluation de modèles
x- Les techniques de ré-échantillonnage en jeu d'apprentissage, de validation et de test.
- Test de représentativité des données d'apprentissage.
x- Mesures de performance des modèles prédictifs.
- Matrice de confusion, de coût et la courbe ROC et AUC.
Travaux pratiques
- Mise en place d'échantillonnage de jeux de donnes. Effectuer des tests d'évaluations sur plusieurs modèles fournis.

3) Les algorithmes supervisés
x- Le principe de régression linéaire univariée.
x- La régression multivariée.
- La régression polynomiale.
- La régression régularisée.
- Le Naive Bayes.
x- La régression logistique.
Travaux pratiques
- Mise en œuvre des régressions et des classifications sur plusieurs types de données.

4) Les algorithmes non supervisés
- Le clustering hiérarchique.
- Le clustering non hiérarchique.
- Les approches mixtes.
Travaux pratiques
-Traitements de clustering non supervisés sur plusieurs jeux de données.

5) Analyse en composantes
x- Analyse en composantes principales.
- Analyse factorielle des correspondances.
- Analyse des correspondances multiples.
- Analyse factorielle pour données mixtes.
- Classification hiérarchique sur composantes principales.
Travaux pratiques
- Mise en œuvre de la diminution du nombres des variables et identification des facteurs sous-jacents des dimensions associées à une variabilité importante.

6) Analyse de données textuelles
- Collecte et prétraitement des données textuelles.
- Les API pour récupérer des données textuelles.
- La préparation des données textuelles en fonction de la problématique.
- La récupération et l'exploration du corpus de textes.
- La suppression des caractères accentués et spéciaux.
- Stemming, Lemmatization et suppression des mots de liaison.
- Tout rassembler pour nettoyer et normaliser les données.
- Extraction d'entités primaires, d'entités nommées et résolution référentielle.
- Étiquetage grammatical, analyse syntaxique, analyse sémantique.
- Lemmatisation.
- Représentation vectorielle des textes.
- Pondération TF-IDF.
x- Word2Vec.
Travaux pratiques
- Explorer le contenu d'une base de textes en utilisant l'analyse sémantique latente.
- La recherche des documents, la préparation, la transformation et la vectorisation des données en DataFrame.

2) Feature Engineering pour la représentation de texte
- Comprendre la syntaxe et la structure du texte.
- Le modèle Bag of Words et Bag of N-Grams.
- Le modèle TF-IDF, Transformer et Vectorizer.
- Le modèle Word2Vec et l’implémentation avec Gensim.
- Le modèle GloVe.
- Le modèle FastText.
Travaux pratiques
- Mise en place des opérations d’extraction des caractéristiques de données textuelles afin d’effectuer des classifications.

3) La similarité des textes et classification non supervisée
- Les concepts essentiels de similarité.
- Analyse de la similarité des termes : distances Hamming, Manhattan, Euclidienne et Levenshtein.
- Analyse de la similarité des documents.
- Okapi BM25 et le palmarès de classement.
- Les algorithmes de classification non supervisée.
Travaux pratiques
- Construire un système de recommandation des produits similaires sur la base de la description et du contenu des produits que vous avez choisi.

4) La classification supervisée du texte
- Prétraitement et normalisation des données.
- Modèles de classification.
- Multinomial Naïve Bayes.
x- Régression logistique. Support Vector Machines.
x- Random Forest. Gradient Boosting Machines.
x- Évaluation des modèles de classification.
Travaux pratiques
- Mise en œuvre des classifications supervisées sur plusieurs jeux de données.

5) Natural Language Processing et Deep Learning
- Les librairies NLP : NLTK, TextBlob, SpaCy, Gensim, Pattern, Stanford CoreNLP.
x- Les librairies Deep Learning : Theano, TensorFlow, Keras.
x- Natural Language Processing et Recurrent Neural Networks.
x- RNN et Long Short-Term Memory. Les modèles bidirectionnels RNN.
x- Les modèles Sequence-to-Sequence.
x- Questions et réponses avec les modèles RNN.
Travaux pratiques
x- Construire un RNN pour générer un nouveau texte.

1) TENSORFLOW
- Créer un premier graphe et l’exécuter dans une session.
- Cycle de vie de la valeur d’un nœud.
- Manipuler des matrices. Régression linéaire. Descente de gradient.
- Fournir des données à l’algorithme d’entraînement.
- Enregistrer et restaurer des modèles. Visualiser le graphe et les courbes d’apprentissage.
- Portées de noms. Partage des variables.
Démonstration
- Présentation des exemples de Machine Learning en classification et régression.

2) Introduction aux réseaux de neurones artificiels
x- Du biologique à l’artificiel.
- Entraîner un PMC (perceptron multicouche) avec une API TensorFlow de haut niveau.
- Entraîner un PMC (perceptron multicouche) avec TensorFlow de base.
- Régler précisément les hyperparamètres d’un réseau de neurones.

3) Entraînement de réseaux de neurones profonds
x- Problèmes de disparition et d’explosion des gradients.
- Réutiliser des couches pré-entraînées.
- Optimiseurs plus rapides.
- Éviter le sur-ajustement grâce à la régularisation.
- Recommandations pratiques.
Travaux pratiques
- Mise en œuvre d'un réseau de neurones à la manière du framework TensorFlow.

4) Réseaux de neurones convolutifs
- L’architecture du cortex visuel.
x- Couche de convolution.
x- Couche de pooling.
x- Architectures de CNN.
Travaux pratiques
x- Mise en œuvre des CNN en utilisant des jeux de données variés.

5) Deep Learning avec Keras
- Régression logistique avec Keras.
- Perceptron avec Keras.
- Réseaux de neurones convolutifs avec Keras.
Travaux pratiques
- Mise en œuvre de Keras en utilisant des jeux de données variés.

6) Réseaux de neurones récurrents
x- Neurones récurrents.
x- RNN de base avec TensorFlow.
x- Entraîner des RNN. RNN profonds.
x- Cellule LSTM. Cellule GRU.
x- Traitement automatique du langage naturel.
Travaux pratiques
- Mise en œuvre des RNN en utilisant des jeux de données variés.

7) Autoencodeurs
x- Représentations efficaces des données.
- ACP avec un autoencodeur linéaire sous-complet.
- Autoencodeurs empilés.
- Pré-entraînement non supervisé avec des autoencodeurs empilés.
- Autoencodeurs débruiteurs. Autoencodeurs épars. Autoencodeurs variationnels. Autres autoencodeurs.
Travaux pratiques
-Mise en œuvre d'autoencodeurs en utilisant des jeux de données variés.

