# Machine Learning & Deep Learning pour le traitement d'images et des séries temporelles

## Durée

3 jours.

## Prérequis

Programmation Python. Bases de statistiques.

## Objectifs pédagogiques

- Comprendre les clés fondamentales d'une approche Machine ou Deep Learning
- Maîtriser les bases théoriques et pratiques d'architecture et de convergence de réseaux de neurones
- Connaître les différentes architectures fondamentales existantes et maîtriser leurs implémentations fondamentales
- Maîtriser les méthodologies de mise en place de réseaux de neurones, les points forts et les limites de ces outils

## Méthodes pédagogiques

Cette formation se base sur des présentations, des échanges et des travaux pratiques en Keras (TensorFlow 2) qui consituent environ 60% du temps de formation.

## Programme

### Introduction IA, Machine Learning et Deep Learning

- Historique, concepts de base et applications de l'intelligence artificielle loin des fantasmes portés par ce domaine.
- Machine Learning usuel : définition.
- Types de tâches : Supervised Learning, Unsupervised Learning, Reinforcement Learning.
- Machine Learning versus Deep Learning : pourquoi le ML reste aujourd'hui l'état de l'art (Random Forests & XGBoosts) ?

### Concepts fondamentaux d'un réseau de neurones

- Rappel de bases mathématiques.
- Le réseau de neurones : architecture, fonctions d'activation et de pondération des activations précédentes...
- L'apprentissage d'un réseau de neurones : fonctions de coût, back-propagation, stochastic gradient descent...
- Modélisation d'un réseau de neurones : modélisation des données d'entrée et de sortie selon le type de problème.
- Approximer une fonction par un réseau de neurones. Approximer une distribution par un réseau de neurones.
- Optimisations et algorithmes de convergence.

### Convolutional Neural Networks (CNN)

- Présentation des CNNs : principes fondamentaux et applications.
- Fonctionnement fondamental d'un CNN : couche convolutionnelle, utilisation d'un kernel, padding et stride...
- Architectures CNN ayant porté l'état de l'art en classification d'images : LeNet, VGG Networks, Network in Network...

Travaux pratiques : classification d'images, détection d'anomalies dans des images, segmentation d'images.

### Recurrent Neural Networks (RNN)

- Présentation des RNNs : principes fondamentaux et applications.
- Fonctionnement fondamental du RNN : hidden activation, back propagation through time, unfolded version.
- Évolutions vers les GRU (Gated Recurrent Units) et LSTM (Long Short Term Memory).
- Problèmes de convergence et vanising gradient.
- Types d'architectures classiques : prédiction d'une série temporelle, classification...
- Architecture de type RNN Encoder Decoder.

Travaux pratiques : classification et régression sur du texte et des séries temporelles.
