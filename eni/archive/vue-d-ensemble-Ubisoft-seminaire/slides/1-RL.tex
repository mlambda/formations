\documentclass{formation}
\title{Avant de parler de jeux vidéo}
\subtitle{Apprentissage par renforcement}

\begin{document}

\maketitle

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  \imgtw[0.5]{rl}
  où :
  \newline
  $S_t$ est l'état de l'environnement,
  \newline
  $A_t$ l'action effectué par l'agent et
  \newline
  $R_t$ la récompense de l'environnement à l'agent (conséquence de $A_t$)
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  \underline{Des contraintes techniques} :
  \begin{itemize}
  \item L'environnement n'est pas forcément parfaitement modélisable
  \item La récompense n'est pas forcément calculable immédiatement
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  \imgth[0.6]{bourse-ny}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  \begin{center}
    \red{Environnement modélisable ? Récompense calculable ?}
  \end{center}
  \imgth[0.6]{echec}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  \begin{center}
    \red{Environnement modélisable ? Récompense calculable ?}
  \end{center}
  \imgth[0.6]{echec}
  \begin{center}
    $\approx 10^{120}$ parties possibles $\ggg 6 x 10^{85}$
    \newline
    (nombre d'atomes dans l'univers observable)
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  \imgth[0.7]{go}
\end{frame}

\begin{frame}
  \frametitle{Go}
  \begin{minipage}[c]{0.6\linewidth}
    \imgtw[1]{go-regles}
  \end{minipage}\hfill
  \begin{minipage}[c]{0.33\linewidth}
    \begin{center}
      \underline{Go Vs Echecs} \\
      \textbf{Le nombre de coups} \\
      $\approx$ 200 contre $\approx$ 35 \\
      \textbf{Le nombre de tours} \\
      $\approx$ 300 contre $\approx$ 40 \\
      $\Rightarrow$ $\approx 10^{690}\ggg \;\approx 10^{120}$
    \end{center}
  \end{minipage}\hfill
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  \huge Une solution naturelle :
  \newline
  \begin{center}
  \huge LE HASARD !
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  Monte Carlos Tree Search
  \imgtw[1]{montecarlo}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  Monte Carlos Tree Search
  \imgth[0.6]{mcts}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  Crazy Stone (Rémi Coulom) et MoGo (Yizao Wang)
  \newline
  \begin{description}
  \item[octobre 2006 :] MoGo est à $\approx 10^6$ parties générées par coup (9x9)
  \item[mars 2008 :] MoGo bat Catalin Taranu (5 dan) (9×9)
  \item[août 2008 :] MoGo bat Kim Myungwan (9 dan) à 9 pierres
  \item[septembre 2008 :] Crazy Stone bat Kaori Aoba (4 dan) à 8 pierres
  \item[décembre 2008 :] Crazy Stone bat Kaori Aoba (4 dan) à 7 pierres
  \item[février 2009 :] MoGo bat Li-Chen Chien (1 dan) à 6 pierres
  \item[mai 2014 :] Crazy Stone bat Norimoto Yoda (9 dan) avec 4 pierres ($\approx 10^{6}$ parties générées pour chaque coup)
  \end{description}
  \begin{center}
    Progrès de + en + lents et difficiles
  \end{center}
\end{frame}

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
