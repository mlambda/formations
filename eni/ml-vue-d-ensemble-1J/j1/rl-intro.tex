\subsection{Apprentissage par renforcement}



\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  \imgtw[0.5]{rl}
  où :
  \newline
  $S_t$ est l'état de l'environnement,
  \newline
  $A_t$ l'action effectué par l'agent et
  \newline
  $R_t$ la récompense de l'environnement à l'agent (conséquence de $A_t$)
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  \underline{Des contraintes techniques} :
  \begin{itemize}
  \item L'environnement n'est pas forcément parfaitement modélisable
  \item La récompense n'est pas forcément calculable immédiatement
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  \imgth[0.6]{bourse-ny}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  \begin{center}
    \red{Environnement modélisable ? Récompense calculable ?}
  \end{center}
  \imgth[0.6]{echec}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  \begin{center}
    \red{Environnement modélisable ? Récompense calculable ?}
  \end{center}
  \imgth[0.6]{echec}
  \begin{center}
    $\approx 10^{120}$ parties possibles $\ggg 6 x 10^{85}$
    \newline
    (nombre d'atomes dans l'univers observable)
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  \imgth[0.7]{go}
  \begin{center}
    \huge{$\approx 10^{600}$}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  \underline{Des contraintes techniques} :
  \begin{itemize}
  \item L'environnement n'est pas forcément parfaitement modélisable
  \item La récompense n'est pas forcément calculable immédiatement
  \item \red{\textbf{Plannification}}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage par Renforcement}
  \imgth[0.6]{voyageur-commerce}
\end{frame}

