{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain Python implementation of K-Means\n",
    "\n",
    "K-Means is a very simple clustering algorithm (clustering belongs to unsupervised learning). Given a fixed number of clusters and an input dataset the algorithm tries to partition the data into clusters such that the clusters have high intra-class similarity and low inter-class similarity. \n",
    "\n",
    "### Algorithm\n",
    "\n",
    "1. Initialize the cluster centers, either randomly within the range of the input data or (recommended) with some of the existing training examples\n",
    "\n",
    "2. Until convergence  \n",
    "\n",
    "   2.1. Assign each datapoint to the closest cluster. The distance between a point and cluster center is measured using the Euclidean distance.  \n",
    "\n",
    "   2.2. Update the current estimates of the cluster centers by setting them to the mean of all instance belonging to that cluster  \n",
    "   \n",
    "   \n",
    "### Objective function\n",
    "\n",
    "The underlying objective function tries to find cluster centers such that, if the data are partitioned into the corresponding clusters, distances between data points and their closest cluster centers become as small as possible.\n",
    "\n",
    "Given a set of datapoints ${x_1, ..., x_n}$ and a positive number $k$, find the clusters $C_1, ..., C_k$ that minimize\n",
    "\n",
    "\\begin{equation}\n",
    "J = \\sum_{i=1}^n \\, \\sum_{j=1}^k \\, z_{ij} \\, || x_i - \\mu_j ||_2\n",
    "\\end{equation}\n",
    "\n",
    "where:  \n",
    "- $z_{ij} \\in \\{0,1\\}$ defines whether of not datapoint $x_i$ belongs to cluster $C_j$\n",
    "- $\\mu_j$ denotes the cluster center of cluster $C_j$\n",
    "- $|| \\, ||_2$ denotes the Euclidean distance\n",
    "\n",
    "### Disadvantages of K-Means\n",
    "- The number of clusters has to be set in the beginning\n",
    "- The results depend on the inital cluster centers\n",
    "- It's sensitive to outliers\n",
    "- It's not suitable for finding non-convex clusters\n",
    "- It's not guaranteed to find a global optimum, so it can get stuck in a local minimum\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T13:39:31.237035Z",
     "start_time": "2018-03-11T13:39:31.226992Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.datasets import make_blobs\n",
    "np.random.seed(123)\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T13:37:28.102812Z",
     "start_time": "2018-03-11T13:37:28.098597Z"
    }
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T13:39:32.652089Z",
     "start_time": "2018-03-11T13:39:32.331596Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_blobs(centers=4, n_samples=1000)\n",
    "print(f'Shape of dataset: {X.shape}')\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.scatter(X[:,0], X[:,1], c=y)\n",
    "plt.title(\"Dataset with 4 clusters\")\n",
    "plt.xlabel(\"First feature\")\n",
    "plt.ylabel(\"Second feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T13:39:37.138439Z",
     "start_time": "2018-03-11T13:39:37.007026Z"
    }
   },
   "outputs": [],
   "source": [
    "class KMeans():\n",
    "    def __init__(self, n_clusters=4):\n",
    "        self.k = n_clusters\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        Fits the k-means model to the given dataset\n",
    "        \"\"\"\n",
    "        n_samples, _ = data.shape\n",
    "        # initialize cluster centers\n",
    "        self.centers = np.array(random.sample(list(data), self.k))\n",
    "        self.initial_centers = np.copy(self.centers)\n",
    "\n",
    "        # We will keep track of whether the assignment of data points\n",
    "        # to the clusters has changed. If it stops changing, we are \n",
    "        # done fitting the model\n",
    "        old_assigns = None\n",
    "        n_iters = 0\n",
    "\n",
    "        while True:\n",
    "            new_assigns = [self.classify(datapoint) for datapoint in data]\n",
    "\n",
    "            if new_assigns == old_assigns:\n",
    "                print(f\"Training finished after {n_iters} iterations!\")\n",
    "                return\n",
    "\n",
    "            old_assigns = new_assigns\n",
    "            n_iters += 1\n",
    "\n",
    "            # recalculate centers\n",
    "            for id_ in range(self.k):\n",
    "                points_idx = np.where(np.array(new_assigns) == id_)\n",
    "                datapoints = data[points_idx]\n",
    "                self.centers[id_] = datapoints.mean(axis=0)\n",
    "\n",
    "    def l2_distance(self, datapoint):\n",
    "        dists = np.sqrt(np.sum((self.centers - datapoint)**2, axis=1))\n",
    "        return dists\n",
    "\n",
    "    def classify(self, datapoint):\n",
    "        \"\"\"\n",
    "        Given a datapoint, compute the cluster closest to the\n",
    "        datapoint. Return the cluster ID of that cluster.\n",
    "        \"\"\"\n",
    "        dists = self.l2_distance(datapoint)\n",
    "        return np.argmin(dists)\n",
    "\n",
    "    def plot_clusters(self, data):\n",
    "        plt.figure(figsize=(12,10))\n",
    "        plt.title(\"Initial centers in black, final centers in red\")\n",
    "        plt.scatter(data[:, 0], data[:, 1], marker='.', c=y)\n",
    "        plt.scatter(self.centers[:, 0], self.centers[:,1], c='r')\n",
    "        plt.scatter(self.initial_centers[:, 0], self.initial_centers[:,1], c='k')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing and fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T13:39:38.433011Z",
     "start_time": "2018-03-11T13:39:38.324276Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot initial and final cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T13:39:41.649052Z",
     "start_time": "2018-03-11T13:39:41.218985Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans.plot_clusters(X)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
