\documentclass{formation}

\title{Régressions linéaire et logistique, réseaux de neurones}
\subtitle{Module 4}

\begin{document}

\maketitle

\section{Objectifs}
\begin{frame}
  \frametitle{Objectifs}
  \begin{itemize}
  \item maîtriser les algorithmes de régressions linéaire et
    logistique
  \item comprendre comment fonctionne et s'entraîne un réseau de
    neurones
  \end{itemize}
\end{frame}

\section{Avant propos}

\begin{frame}
  \frametitle{Avant propos}

  \begin{itemize}
  \item régression linéaire = plus simple des réseaux de neurones
  \item régression logistique = très légère variation sur régression
    linéaire qui permet de classifier
  \item bases qui serviront à comprendre les réseaux de neurones
    généraux
  \end{itemize}

  Plan du cours :
  \begin{itemize}
  \item introduction aux réseaux de neurones
  \item régression linéaire
  \item régression logistique
  \item réseaux de neurones généraux
  \end{itemize}
\end{frame}

\section{Introduction aux réseaux de neurones}

\begin{frame}
  \frametitle{Réseaux de neurones}
  Intuition:
  \begin{tabbing}
    1M neurones \=\kill
    1 neurone \>= 1 calcul simple\\
    1M neurones \>= 1M calculs simples\\
    \>= 1 calcul complexe\\
  \end{tabbing}
\end{frame}

\begin{frame}
  \frametitle{Réseaux de neurones}
  \imgtw{neural-network}
\end{frame}

\begin{frame}
  \frametitle{Neurone biologique}
  \imgtw{biological-neuron}
\end{frame}

\begin{frame}
  \frametitle{Neurone artificiel}
  Simulation extrêmement basique d'un neurone: somme pondérée +
  activation.
  \imgth[0.6]{neuron-model}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage}
  Modification des poids des neurones (poids des sommes).

  But : la somme finale = output attendu.
\end{frame}

\begin{frame}
  \frametitle{Fonction de perte (rappel module 3)}

  Mesurer la qualité du modèle :

  \[
    L(\vect{\hat{y}}, \vect{y})
  \]

  Plus cette perte est proche de 0, meilleur est le modèle.
\end{frame}


\begin{frame}
  \frametitle{Apprentissage --- modélisation}
  Apprendre = minimiser la fonction de perte.

  \[
    \argmin_{\vect{\hat{y}}}L(\vect{\hat{y}}, \vect{y})
  \]
\end{frame}

\begin{frame}
  \frametitle{Apprentissage --- optimisation par descente du gradient}
  Minimisation de $L$ en allant à l'opposé du gradient, par pas de
  taille $\alpha$.

  \[
    w \leftarrow w - \alpha \nabla_wL
  \]
  
\end{frame}

\begin{frame}
  \frametitle{Apprentissage --- optimisation par descente du gradient}

  \imgtw[.6]{gradient-descent}
\end{frame}

\section{Régression linéaire}

\begin{frame}
  \frametitle{Régression linéaire simple}
  Étant donné une variable en entrée, prédire une variable continue en
  sortie.

  \textbf{Contrainte très forte : $\hat{y}_i = \theta_0+\theta_1 x_i$}

  \imgtw[.6]{regression}
\end{frame}
\begin{frame}
  \frametitle{Exemple}

  Prédiction de vos bénéfices après un an étant donné les actions que
  vous avez chez Airbus :
  \begin{description}
  \item[Input] $500$
  \item[Output] $37$
  \end{description}
\end{frame}

\begin{frame}
  \frametitle{Régression linéaire simple}

  Trouver les meilleurs $\theta_0$ et $\theta_1$ avec:

  \[
    \vect{\hat{y}} = \theta_0 + \theta_1\vect{x}
  \]
\end{frame}

\begin{frame}
  \frametitle{Définition d'une fonction de perte}

  Pour savoir si nos $\theta_0$ et $\theta_1$ sont bons:

  \begin{itemize}[<+->]
  \item calcul de $\hat{y_i}$ pour chaque $x_i$ du training set
  \item calcul des $y_i - \hat{y}_i$ (résiduels)
  \item grands résiduels = mauvais modèle
  \end{itemize}
  \onslide<+->{→ Fonction de perte = mesurer la taille des résiduels}
\end{frame}

\begin{frame}
  \frametitle{Fonction de perte}

  Pour un seul exemple, la perte est définie comme:
  \[
    L(\hat{y}_i, y_i) = (y_i - \hat{y}_i)^2
  \]
  Pour tous les exemples, on la définit comme la moyenne des pertes:
  \[
    L(\vect{\hat{y}}, \vect{y}) = \frac{(\vect{\hat{y}} - \vect{y})^2}{n}
  \]

  avec $n$ taille du dataset.
\end{frame}

\begin{frame}
  \frametitle{Apprentissage}

  \begin{itemize}
  \item solution directe existe pour les petits datasets
  \item descente de gradient dans la pratique (s'adapte à tout)
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage}

  Algorithme :
  \begin{itemize}
  \item calculer le gradient de $\theta$ par rapport à $L$
  \item ajuster $\theta$ avec la règle
    $\theta \leftarrow \theta - \alpha \nabla_\theta L$
  \item répéter jusqu'à \texttt{max\_iter} itérations ou convergence
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage}

  \imgtw[.6]{gradient-descent}
\end{frame}

\begin{frame}
  \frametitle{Régression linéaire multiple}

  Étant donné plusieurs variables en entrée, prédire une variable
  continue en sortie.

\end{frame}

\begin{frame}
  \frametitle{Exemple}
  Prédiction de vos bénéfices après un an étant donné votre
  portfolio :
  \begin{description}
  \item[Inputs] $[(\text{LVMH}, 2000), (\text{TOTAL}, 1500), (\text{AIRBUS}, 500)]$
    \item[Output] 42
  \end{description}
\end{frame}

\begin{frame}
  \frametitle{Modélisation}
    Trouver les meilleurs $\theta_0$ à $\theta_n$ avec:

  \[
    y_i = \theta_0 + \sum_{k = 1}^{n}\theta_kx_{ik}
  \]
\end{frame}

\begin{frame}
  \frametitle{Apprentissage}

  Même algorithme que pour la régression linéaire simple !
\end{frame}

\begin{frame}
  \frametitle{Limitations}

  \begin{itemize}
  \item \textbf{TRÈS} grosse hypothèse de linéarité
  \item suppose que les variables sont normalement distribuées
  \item dans la pratique, on peut pallier quelques limitations
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Practice time}

  TP : \texttt{day2/Linear regression.ipynb}
\end{frame}

\section{Régression logistique}

\begin{frame}
  \frametitle{Régression logistique}
  Étant donné une variable en entrée, prédire une variable continue en
  sortie, \textbf{dans $\mathbf{[0, 1]}$.}

  → classification
\end{frame}

\begin{frame}
  \frametitle{Modélisation}
    Trouver les meilleurs $\theta_0$ à $\theta_n$ avec:

  \[
    \hat{y}_i = \sigma(\theta_0 + \sum_{k = 1}^{n}\theta_kx_{ik})
  \]
\end{frame}

\begin{frame}
  \frametitle{Fonction sigmoid}

  \imgtw[.6]{sigmoid}
\end{frame}

\begin{frame}
  \frametitle{Entropie croisée binaire}
  $y_i \in \{0, 1\}$, $\hat{y_i} \in [0,1]$.
  \[
    \BCE(\hat{y}_i, y_i) = y_i\log \hat{y}_i + (1 - y_i)\log (1 -
    \hat{y}_i)
  \]

\end{frame}

\begin{frame}
  \frametitle{Apprentissage}

  Même algorithme que pour la régression linéaire !
\end{frame}


\section{Régression logistique multi-classes}

\begin{frame}
  \frametitle{Régression logistique multi-classes}
  Étant donné des variables en entrée, prédire $n$ variable dans
  $\{0, 1\}$ en sortie, avec $\mathbf{\sum_{i = 1}^n y_i = 1}$.

  → output = loi de probabilité
\end{frame}

\begin{frame}
  \frametitle{Idée clef}
  \begin{itemize}
  \item mener $n$ régressions linéaires en parallèle (avoir $n$
    neurones d'output)
  \item ajouter une normalisation pour garantir que l'output somme à 1
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Normalisation}

  Utilisation d'un softmax :
  \[
    \softmax(\mathbf{z})_i = \frac{e^{z_i}}{\sum_{k=1}^n e^{z_k}}
  \]
  \begin{itemize}[<+->]
  \item besoin de tous les outputs pour normaliser
  \item somme à 1
  \item produit des sorties plutôt sparse (compresse vers 0 et 1)
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage}

  Encore une fois, l'apprentissage ne change pas.

\end{frame}

\begin{frame}
  \frametitle{Practice time}

  TP : \texttt{day2/Logistic regression.ipynb}
\end{frame}

\section{Réseaux de neurones généraux}

\begin{frame}
  \frametitle{Différences avec les régression linéaires et
    logistiques}

  \begin{itemize}
  \item pas seulement une couche d'output (profondeur)
  \item pas seulement des fonctions linéaires (activations)
  \item des types de neurones particuliers pour certains réseaux
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Profondeur}

  \imgtw[.7]{deep-net}

  → nécessité d'adapter l'apprentissage
\end{frame}

\begin{frame}
  \frametitle{Non-linéarité}

  \begin{columns}
    \begin{column}{.5\tw}
      \imgtw{xor}
      
    \end{column}
    \begin{column}{.5\tw}
      \imgtw{neuron-model}
    \end{column}
  \end{columns}

  → $f$ non linéaire nécessaire ! (sigmoid, tanh, ReLU, …)
\end{frame}

\begin{frame}
  \frametitle{Non-linéarité}

  \imgtw[.6]{sigmoid}
\end{frame}

\begin{frame}
  \frametitle{Apprentissage}

  \begin{itemize}
  \item définition de perte
  \item descente de gradient
  \item si réseau profond, nécessité de calculer beaucoup de dérivées
  \end{itemize}

  → utilisation d'une règle de chainage pour ne pas tout recalculer
\end{frame}

\begin{frame}
  \frametitle{Règle de chainage --- cas simple}
  \imgth[.5]{monopath}

  \[
    \frac{\partial y}{\partial x} = \frac{\partial y}{\partial h}
    \frac{\partial h}{\partial x}
  \]
\end{frame}


\begin{frame}
  \frametitle{Règle de chainage --- deux chemins}
  \imgth[.5]{multipaths}

  \[
    \frac{\partial y}{\partial x} = \frac{\partial y}{\partial h_1}
    \frac{\partial h_1}{\partial x} + \frac{\partial y}{\partial h_2}
    \frac{\partial h_2}{\partial x}
  \]
\end{frame}

\begin{frame}
  \frametitle{Diversité des fonctions de pertes}

  Il existe des pertes :
  
  \begin{itemize}[<+->]
  \item pour des classements
  \item pour des objectifs multiples
  \item avec des propriétés mathématiques particulières
  \item avec des gains de temps d'entrainement
  \item modélisées par des réseaux de neurones (!!!)
  \end{itemize}

  \onslide<+->{Il existe sûrement une loss pour votre problème
    spécifique !}
\end{frame}

\section{Conclusion}

\begin{frame}
  \frametitle{Conclusion}
  \begin{itemize}
  \item neurone = somme pondérée (+ activation pour les réseaux
    généraux)
  \item apprentissage = trouver les bons poids des sommes
  \item métrique = fonction de perte
  \item technique = rétropropagation des gradients
  \item régression linéaire = régression, régression logistique =
    classification
  \item les deux sont des réseaux de neurones sans couche cachée
  \end{itemize}
\end{frame}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
