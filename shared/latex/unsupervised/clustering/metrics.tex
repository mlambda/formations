\begin{frame}{Métriques de clustering --- Introduction}
  Deux cas~:

  \begin{enumerate}[<+->]
    \item Si on dispose de données annotées (même insuffisantes pour apprendre) $\rightarrow$ métriques supervisées de classification
    \item Sinon, on évalue la qualité \emph{intrinsèque} des clusters
  \end{enumerate}

\end{frame}

\begin{frame}{Métriques de clustering --- Application des métriques supervisées}
  Un calcul préalable est nécessaire~: le mapping optimal entre les clusters et les labels.

  Plusieurs possibilités~:

  \begin{itemize}[<+->]
    \item Algorithme hongrois
    \item Sous-optimal mais bonne première approche~: classe la plus représentée dans chaque cluster
  \end{itemize}
\end{frame}

\begin{frame}{Métriques de clustering --- Inertie}
  \begin{center}
    coût = $\sum_i \sum_j \delta_{i,j}\lVert x_j - \mu_i \rVert^2$
  \end{center}
  où $\delta_{i,j}$ vaut 1 si le cluster $\mu_i$ est le plus proche du point $x_j$, 0 sinon
\end{frame}

\begin{frame}{Métriques de clustering --- Silhouette}
  Points $x = \{x_1, \dotsc, x_n\}$ , Clusters $\mu = \{\mu_1, \dotsc, \mu_k\}$ et $x_i\in\mu_I$. \\
  \[
  \boxed{a(x_i) = \frac{1}{|\mu_I|-1}\sum_{j\in|\mu_I|, i \neq j} |x_i - x_j|}
  \]
  \[
  \boxed{b(x_i) = \min_{I \neq J} \frac{1}{|\mu_J|}\sum_j |x_i - x_j|}
  \]
  où : \\
  $|\mu_I|$ est le nombre d'éléments de x dans le cluster $\mu_I$ \\
  $a(x_i)$ : distance moyenne aux autres points du cluster contenant $x_i$ \\
  $b(x_i)$ : distance moyenne aux points du cluster le plus proche ne contenant pas $x_i$
  
\end{frame}

\begin{frame}{Métriques de clustering --- Silhouette}
  Points $x = \{x_1, \dotsc, x_n\}$ , Clusters $\mu = \{\mu_1, \dotsc, \mu_k\}$. \\
  \[
  \boxed{a_i = \frac{1}{\#\mu_i-1}\sum_j |x_i - x_j|}
  \]
  \[
  \boxed{b_i = \min_{i \neq j} \frac{1}{\#\mu_j}\sum_j |x_i - x_j|}
  \]
  où : \\
  $\#\mu_i$ est le nombre d'éléments de x dans le cluster $\mu_i$ \\
  L'ensembe d'indice j ne représente que ceux des points appartenant au cluster $\mu_j$ \\
  $a_i$ : distance moyenne aux autres points du cluster contenant $x_i$ \\
  $b_i$ : distance moyenne aux points du cluster le plus proche
  
\end{frame}

\begin{frame}{Métriques de clustering --- Silhouette}
  
  \begin{center}
    \[
    s_i = \frac{b_i - a_i}{\max\{a_i, b_i\}}\;\;,\;\;
    s_i = \left\{
    \begin{array}{ll}
      1 - a_i/b_i & \mbox{ if } a_i < b_i \\[2mm]
      0 & \mbox{ if } a_i = b_i \\[2mm]
      b_i / a_i - 1 & \mbox{ if } a_i > b_i
    \end{array}\right.
    \]
    
  \end{center}
  donc $s_i \in [-1, 1]$ \\
  \\
  $s_i \approx 1 \iff$ $x_i$ bien clusterisé \\
  $s_i \approx 0 \iff$ $x_i$ au bord de 2 clusters\\
  $s_i \approx -1 \iff$ $x_i$ mal clusterisé
\end{frame}

\begin{frame}{Métriques de clustering --- Et d'autres options existent}
  \begin{itemize}
  \item Calinski-Harabaz index : Comparaison densité inter et intra cluster (sans borne. Plus le score est élevé, plus le clustering est bon)
  \item Davies-Bouldin Index : Mesure de similarité des clusters (Plus le score est faible, plus le clustering est bon)
  \item ...
  \end{itemize}
\end{frame}
