
\begin{frame}{Clustering Hiérarchique}
  Deux approches~:

  \begin{itemize}[<+->]
    \item Agglomératives (bottom-up)
    \item Divisantes (top-down), moins utilisées
  \end{itemize}
\end{frame}

\begin{frame}{Clustering Hiérarchique --- Procédé}
  Méthode Agglomérative

  \begin{description}[<+->]
    \item[Initialisation] Chaque élément est dans une classe distincte
    \item[Aggrégation] Itérativement, fusion deux par deux les classes les plus similaires
    \item[Exploitation] On choisit le nombre de clusters à exploiter
  \end{description}
\end{frame}

\begin{frame}{Clustering Hiérarchique --- Résultat}
  \imgth{dendogram}{0.8}
\end{frame}

\begin{frame}{Clustering Hiérarchique --- Procédé}

  Pour décider des clusters les plus similaires (à fusionner donc), plusieurs options~:

  \begin{description}[<+->]
  \item[Saut minimum] $\underset{x \in C_1,y \in C_2}{\min}{D(x,y)}$
  \item[Saut maximum] $\underset{x \in C_1,y \in C_2}{\max}{D(x,y)}$
  \item[Saut moyen] $\underset{x \in C_1,y \in C_2}{\mean}{D(x,y)}$
  \item[Méthode de Ward] Maximise l'inertie inter-classe
  \item ...
  \end{description}

  \onslide<+->{Méthode exacte~: $O(n^2)$ < complexité < $O(n^3)$ !}
\end{frame}
