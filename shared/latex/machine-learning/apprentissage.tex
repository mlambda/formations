\begin{frame}
  \frametitle{Qualité de l'apprentissage}
  Entrainement supervisé d'un modèle — overfit

  \V{["fit-nzmog", "tw", 1] | image}

  \red{Problème : trop minimiser la perte n'est pas bon !}
\end{frame}

\begin{frame}
  \frametitle{Qualité de l'apprentissage}

  \V{["learning-curve-nzmog", "th", 0.6] | image}

  → Minimiser la perte sur un ensemble de validation
\end{frame}

\begin{frame}
  \frametitle{Séparation des données}
  \begin{itemize}
  \item ensemble d'entrainement
  \item ensemble de validation pour mesurer la généralisation
  \item ensemble de test (pour éviter le biais statistique)
  \end{itemize}
  → Split 60/20/20 habituel.
\end{frame}

\begin{frame}
  \frametitle{Cross-validation}
  Pour \og perdre\fg{} moins de données et mieux tester la
  généralisation :
  \V{["k-fold-cross-validation", "tw", 0.9] | image}
  Ici, 4-fold cross-validation.
\end{frame}

