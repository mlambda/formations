\begin{frame}{Modèle à attention}
  \begin{center}
    \bluelink{https://demo.allennlp.org/reading-comprehension}{Démo modèle à attention}
  \end{center}
\end{frame}

\notmog{
  \begin{frame}{Réseaux transformeurs}
    \V{"img/transformer-fun" | image("tw", 0.9)}
  \end{frame}
}

\begin{frame}{Vue générale}
  \V{"img/transformer-network-1" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Architecture encodeur-décodeur}
  \V{"img/transformer-network-2" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Architecture encodeur-décodeur --- Rappel}
  Rappelez-vous, les encodeurs-décodeurs :
  \V{"img/rnn-seq2seq" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Architecture profonde}
  Couches «~simples~» empilées~:
  \V{"img/transformer-network-3" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Architecture globale de l'encodeur et du décodeur}
  \V{"img/transformer-network-5" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Architecture globale de l'encodeur}
  \V{"img/transformer-network-4" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Forme des données en jeu dans l'encodeur}
  \V{"img/transformer-network-7" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Forme des données en jeu dans l'encodeur}
  \V{"img/transformer-network-8" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Self-Attention --- Éléments utilisés}
  \V{"img/transformer-network-9" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Self-Attention --- Combinaison des éléments}
  \V{"img/transformer-network-13" | image("th", 0.9)}
\end{frame}

\begin{frame}{Self-Attention --- Obtention du résultat}
  \V{"img/transformer-network-14" | image("tw", 0.9)}
  Avec le softmax défini ainsi : $\sigma(z_j)=\frac {\mathrm{e}^{z_j}}{\sum _{k=1}^{K}\mathrm{e}^{z_{k}}}$
\end{frame}

\begin{frame}{Self-Attention --- Run sur 2 mots}
  \V{"img/transformer-network-10" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Self-Attention --- Run sur 2 mots}
  \V{"img/transformer-network-11" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Self-Attention --- Run sur 2 mots}
  \V{"img/transformer-network-12" | image("th", 0.9)}
\end{frame}

\begin{frame}{Self-Attention --- Visualisation}
  \V{"img/transformer-network-self-attention" | image("th", 0.9)}
\end{frame}

\begin{frame}{Attention multi-têtes --- Têtes d'attention}
  \V{"img/transformer-network-15" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Attention multi-têtes --- Combinaison}
  \V{"img/transformer-network-16" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Encodeur --- Résumé}
  Un modèle sans récurrence, uniquement des sommes pondérées.

  \V{"img/transformer-network-17" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Encodeur --- Gestion de la position}
  Pour l'instant, modèle invariant à l'ordre.

  $\Rightarrow$ Nécessité d'encoder la position (encodage positionnel).
\end{frame}

\begin{frame}{Encodeur --- Encodage positionnel --- Fonction hardcodée}
  \V{"img/transformer-network-18" | image("tw", 0.9)}
  $\text{PE}_{\text{pos}, 2i} = \sin{(\text{pos} / 10000^{2i / d_{\text{model}}})}$ \\
  $\text{PE}_{\text{pos}, 2i + 1}= \cos{(\text{pos} / 10000^{2i / d_{\text{model}}})}$
\end{frame}

\begin{frame}{Encodeur --- Encodage positionnel --- Alternative}
  Il est aussi possible d'apprendre les embeddings de position, sans détérioration des performances.
\end{frame}

\begin{frame}{Encodeur --- Encodage positionnel --- Exemple}
  \V{"img/transformer-network-19" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Encodeur --- Encodage positionnel --- Visualisation}
  \V{"img/positional-encoding" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Décodeur --- Exemple de décodage}
  \V{"img/transformer-decoding-init-0" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Décodeur --- Exemple de décodage}
  \V{"img/transformer-decoding-init-157" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Décodeur --- Exemple de décodage}
  \V{"img/transformer-decoding-0" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Décodeur --- Exemple de décodage}
  \V{"img/transformer-decoding-14" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Décodeur --- Exemple de décodage}
  \V{"img/transformer-decoding-38" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Décodeur --- Exemple de décodage}
  \V{"img/transformer-decoding-91" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Décodeur --- Exemple de décodage}
  \V{"img/transformer-decoding-112" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Décodeur --- Exemple de décodage}
  \V{"img/transformer-decoding-137" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Décodeur --- Exemple de décodage}
  \V{"img/transformer-decoding-188" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Décodeur --- Exemple de décodage}
  \V{"img/transformer-decoding-207" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Décodeur --- Exemple de décodage}
  \V{"img/transformer-decoding-234" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Décodeur --- Exemple de décodage}
  \V{"img/transformer-decoding-306" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Décodeur --- Exemple de décodage}
  \V{"img/transformer-decoding-333" | image("tw", 0.9)}
\end{frame}

\begin{frame}{Transformer Network}
  Les illustrations sont tirées du billet de blog de Jay Alammar~:
  \url{http://jalammar.github.io/illustrated-transformer/}
\end{frame}
