\begin{frame}{Sur-apprentissage (et sous-apprentissage)}
  \V{"plt/overfitting-train" | image("th", 0.7)}
\end{frame}

\begin{frame}{Par la pénalisation de l'utilisation des paramètres}
  Coût supplémentaire pour l'utilisation des paramètres dans la fonction de perte~:
  \begin{description}
    \item[L1] Produit beaucoup de poids à 0, s'appelle aussi Lasso~:
      \[
        E = E + \lambda ||\vect{\theta}||_1
      \]
    \item[L2] Pénalise les très gros poids, s'appelle aussi Ridge~:
      \[
        E = E + \lambda ||\vect{\theta}||_2^2
      \]
  \end{description}

  où $\lambda$ est un hyperparamètre
\end{frame}

\begin{frame}{Par early stopping}
  \V{"plt/early-stopping" | image("th", 0.7)}
\end{frame}

\begin{frame}{Par augmentation/bruitage des données}
  \V{"plt/data-augmentation" | image("tw", 1.0)}
\end{frame}

\begin{frame}{Par dropout}
  \V{"tikz/neural-networks/dropout" | image("tw", 1)}
\end{frame}

\begin{frame}{En entraînant sur plusieurs tâches}
  \V{"img/multi-task-v2" | image("tw", 0.8)}
\end{frame}

\begin{frame}{En opposant des réseaux de neurones}
  \V{"tikz/neural-networks/gan/gan" | image("tw", 0.8)}
\end{frame}
