default_titles:
  attention-model: Modèle à attention
  deep-optimize: Optimisation de réseaux profonds
  gan-intro: Petit jeu de rapidité
  gan-models: Generative Adversarial Network (GAN)
  gradient-descent: Descente de gradient
  intro: Introduction
  lstm: Réseaux à longue mémoire de court terme
  optimize: Optimisation des hyper-paramètres
  regularisation: Régularisation
  rnn: Réseaux de neurones récurrents
  rnn-keras: Utilisation dans Keras
  rnn-variants: Variantes de réseaux récurrents
  tp-nn: Travaux Pratiques --- Tensorflow et Keras
  tp-nn-tf: Travaux Pratiques --- Réseau de neurones avec Tensorflow
  tp-rnn: Travaux Pratiques --- RNN
  tp-rnn-text: Travaux Pratiques --- RNN --- Classification de texte
  tp-transformer: Travaux Pratiques --- Transformeurs
  transformer: Réseaux transformeurs
flavors:
  deep-discover:
    - intro
    - optimize
    - deep-optimize
    - regularisation
    - online-demo 
    - gan-intro
    - gan-model
    - $cnn: model-light
    - $rnn: model-light
  deep-discover-demo:
    - intro
    - demo-nn
    - optimize
    - deep-optimize
    - regularisation
    - online-demo
    - $cnn: demo
    - $rnn: demo
    - gan-intro: Réseaux adverses
    - gan-model
    - demo-gan
    - /questions
  deep-detailed-demo:
    - intro
    - demo-nn
    - optimize
    - deep-optimize
    - regularisation
    - online-demo
    - $cnn: demo
    - $rnn: demo-detailed
    - gan-intro: Réseaux adverses
    - gan-model
    - demo-gan
    - /questions
  deep-intro:
    - intro
    - gradient-descent
    - optimize
    - deep-optimize
    - regularisation
    - online-demo
    - /questions
  gan-intro:
    - gan-intro
    - gan-model
    - /questions
  intro-cnn:
    - intro
    - online-demo
    - $cnn: model-light
  ml5j:
    - intro
    - gradient-descent
    - optimize
    - deep-optimize
    - regularisation
    - online-demo
    - /questions
    - tp-nn
    - $cnn: full
    - gan-intro
    - gan-model
    - $rnn: model
  recurrent-text:
    - intro
    - optimize
    - deep-optimize
    - regularisation
    - $rnn: full
  tp-nn-keras:
    - tp-nn: null
  tp-tf-pur:
    - tp-nn-tf: null
  transformer:
    - attention-model
    - transformer: Méthode
    - /questions
    - tp-transformer: Travaux Pratiques
title: Réseaux de neurones
version: 3
