\begin{frame}{Qualité de l'apprentissage}
  Entrainement supervisé d'un modèle — overfit

  \V{["plt/overfit-polynomial", "tw", 1] | image}

  \red{Problème : trop minimiser la perte n'est pas bon !}
\end{frame}

\begin{frame}{Qualité de l'apprentissage}

  \V{["plt/learning-curve", "th", 0.6] | image}

  → Minimiser la perte sur un ensemble de validation
\end{frame}

\begin{frame}{Séparation des données}
  \begin{itemize}
  \item ensemble d'entrainement
  \item ensemble de validation pour mesurer la généralisation
  \item ensemble de test (pour éviter le biais statistique)
  \end{itemize}
  → Split 60/20/20 habituel.
\end{frame}

\begin{frame}{Cross-validation}
  Pour \og perdre\fg{} moins de données et mieux tester la
  généralisation :
  \V{["img/k-fold-cross-validation", "tw", 0.9] | image}
  Ici, 4-fold cross-validation.
\end{frame}

\begin{frame}{Régularisation}
  \begin{minipage}[l]{0.49\linewidth}
    \begin{center}
      Régularisation \\
      $\approx$\\
      empêcher le surapprentissage
    \end{center}
  \end{minipage}\hfill
  \begin{minipage}[l]{0.49\linewidth}
    \V{["img/overfitting-train-nzmog", "th", 0.3] | image}
  \end{minipage}\hfill
  Techniques variées en fonction du modèle :
  \begin{itemize}
  \item Pénalisation de la norme des paramètres
  \item Bruitage
  \item Dropout
  \item …
  \end{itemize}
\end{frame}

\begin{frame}{Optimisation des méta-paramètres}
  Méta-paramètres : paramètres \alert{non appris} par le modèle.
  \begin{exampleblock}{Exemples}
  \begin{description}
  \item[Forme] Nombre de couches ? De quelles tailles ? …
  \item [Optimisation] SGD, AdaBoost, Adam, …
  \item [Régularisation] Pénalisation de la Norme des paramètres dans la loss, bruitage, dropout, …
  \end{description}
  \end{exampleblock}
  Optimisation par recherche aléatoire ou processus gaussien.
\end{frame}
