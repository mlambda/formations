\begin{frame}{Buts}
  \begin{itemize}[<+->]
    \item Mesurer la qualité des prédictions du modèle
    \item Évaluer si un modèle peut remplir un objectif métier
    \item Se protéger des régressions (détériorations) après mise à jour
  \end{itemize}
\end{frame}

\begin{frame}{Évaluation de modèles de régression}
  \begin{columns}
    \begin{column}{.48\textwidth}
      \V{"img/regression-error" | image("tw", 1)}
    \end{column}
    \begin{column}{.70\textwidth}
      \begin{itemize}
        \item Racine carré de l'erreur quadratique moyenne $$RMSE(\hat{Y}, Y) = \sqrt{\frac{1}{n} \sum_{i=1}^n (\hat{Y_i} - Y_i)^2}$$
        \item Erreur absolue moyenne $$MAE(\hat{Y}, Y) = \frac{1}{n} \sum_{i=1}^n |Y_i - \hat{Y_i}|$$
        \item R2 score $$R^2(\hat{Y}, Y) = 1 - \frac{\sum_{i=1}^n (Y_i - \hat{Y_i})^2}{\sum_{i=1}^n (Y_i - \bar{Y})^2}$$
      \end{itemize}
    \end{column}
  \end{columns}
  
\end{frame}

\begin{frame}{Évaluation de modèles de classification}
  Les deux premières métriques sont les plus utilisées:
  \begin{description}
  \item[Précision]
    \[
    \frac{\text{vrais positifs}}{\text{vrais positifs + faux positifs}}
    \]
  \item[Rappel]
    \[
    \frac{\text{vrais positifs}}{\text{vrais positifs + faux négatifs}}
  \]
  \item[F-mesure] Moyenne harmonique entre précision et rappel (aussi appelée score F1)
  \end{description}
\end{frame}

\begin{frame}{Illustration de la précision et du rappel}
  \V{"img/precisionrecall" | image("th", 0.7)}
\end{frame}

\begin{frame}{Espace ROC}
  Mesure la performance du modèle à plusieurs seuils de décision.
  \begin{columns}
    \begin{column}{.48\textwidth}
      \textbf{Abscisse}

      1 - spécificité, taux de faux positifs, ou probabilité de \emph{fausse alerte} ($\frac{\text{FP}}{\text{VN} + \text{FP}}$)
 
      \vspace{1cm}
      \textbf{Ordonnée}
  
      Sensibilité, taux de vrais positifs ou rappel ($\frac{\text{VP}}{\text{VP} + \text{FN}}$)
    \end{column}
    \begin{column}{.52\textwidth}
      \V{"img/roc-space" | image("tw", 0.8)}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{Matrice de confusion}
  Montrer clairement quelles sont les erreurs faites par le modèle
  \V{"img/confusion-matrix-nzmog" | image("th", 0.6)}
\end{frame}
