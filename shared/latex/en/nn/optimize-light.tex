\begin{frame}{What are hyperparameters?}
  \begin{columns}
    \begin{column}[c]{0.5\textwidth}
      \V{"tikz/neural-networks/deep-ff-notext" | image("tw", 1, "en")}
    \end{column}
    \begin{column}[c]{0.5\textwidth}
      \begin{itemize}
        \item Learning rate
        \item Batch size
        \item Number of layers
        \item Size of layers
        \item …
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{Approach to optimize hyperparameters}
  \begin{itemize}
    \item Start with good baselines and a simple “manual” search
    \item When you are done with the basic pipeline, implement a proper search using a dedicated library
  \end{itemize}
\end{frame}

\begin{frame}{Beyond manual tuning}
  Training models is extremely costly.
  A good navigation in the hyperparameters space is important.

  $\Rightarrow$ Use a dedicated library like Keras Tuner, Hyperopt, Nevergrad, Optuna or Ray to leverage Gaussian Processes and similar state of the art methods.
\end{frame}
