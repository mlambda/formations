\begin{frame}{Introduction}
  Naive Bayes classification is:
  \begin{itemize}[<+(1)->]
    \item simple to compute
    \item simple to formulate
    \item often a good first baseline
    \item limited by its strong hypotheses
  \end{itemize}
\end{frame}

\begin{frame}{Bayesian reasoning}
  \begin{itemize}
    \item Formulate an hypothesis without looking at annotated data (prior probability)
    \item Update the hypothesis based on the available data (posterior probability)
  \end{itemize}
\end{frame}

\begin{frame}{Notation}
  For the following slides, we will use the following notation:

  \begin{description}[<+(1)->]
    \item[$C$] Random variable for the class of a sample
    \item[$C_k$] Possible classes (possible values of $C$)
    \item[$F$] Random variable for the sample features
    \item[$F_i$] Feature values for sample $i$
  \end{description}
\end{frame}

\begin{frame}{Computation of the class of a sample}
  Bayes theorem:
  \[
    P(C = C_k \mid F = F_i) = \frac{P(C = C_k) \times P(F = F_i \mid C = C_k)}{P(F = F_i)}
  \]

  Where:

  \begin{description}
    \item[$P(C = C_k \mid F = F_i)$] Posterior probability
    \item[$P(C = C_k)$] Prior probability
    \item[$P(F = F_i \mid C = C_k)$] Likelihood
    \item[$P(F = F_i)$] Prior probability
  \end{description}
  %TODO evidence
\end{frame}

\begin{frame}{Example --- Goal}
  \def\banane{\text{banana}}%
  \def\orange{\text{orange}}%
  \def\tomate{\text{tomato}}%
  \def\jaune{\text{yellow}}%
  \def\longg{\text{long}}%
  \def\sucre{\text{sweet}}%

  Dataset of fruits (bananas, oranges and tomatoes).

  Features: \text{color}, \text{size}, \text{sweetness}.

  For a \jaune{}, \longg{} and \sucre{} sample, naive bayes prediction is the maximum among
  \begin{itemize}
  \item $P(C = \banane \mid F = \jaune \land \longg \land \sucre)$
  \item $P(C = \orange \mid F = \jaune \land \longg \land \sucre)$
  \item $P(C = \tomate \mid F = \jaune \land \longg \land \sucre)$
  \end{itemize}
\end{frame}

\begin{frame}{Example --- Computation}
  \def\banane{\text{banana}}%
  \def\orange{\text{orange}}%
  \def\tomate{\text{tomato}}%
  \def\jaune{\text{yellow}}%
  \def\longg{\text{long}}%
  \def\sucre{\text{sweet}}%
  Naive classification: variables are considered independent, so:

  \begin{center}
    $P(C = \banane \mid F = \jaune \land \longg \land \sucre) =$\\
    $\;$\\
    $ \frac{P(\jaune \mid \banane) \times P(\longg \mid \banane) \times P(\sucre \mid \banane) \times P(\banane)}%
    {P(\jaune) \times P(\longg) \times P(\sucre)}$
  \end{center}
  To compute those probabilities, we \emph{count} in our fruit dataset:

  \[
    P(\sucre \mid \banane) = \frac{\card{\banane \land \sucre}}{\card{\banane}}
  \]
\end{frame}
