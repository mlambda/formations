\begin{frame}
  \frametitle{SVD}
  Utiilisation de SVD pour réduire le nombre de dimensions du problème.
  $M = U^p*V^p*I^p$,  où : \\
  $M$ est la matrice user/item de $\mathbf{R}^{n*m}$ \\
  $U^p$ la matrice des vecteurs de base orthonormée de $\mathbf{R}^{n}$ (input) \\
  $V^p$ la matrice diagonale des valeurs singulières de $U$ \\
  $I^p$ la matrice des vecteurs de base orthonormée de $\mathbf{R}^{m}$ (output) \\
  M = 
  \begin{tabular}{|c|c|c|}
    \hline
    2 & 5 & ? \\
    \hline
    1 & 4 & 3 \\
    \hline
    ? & 1 & 5 \\
    \hline
    3 & ? & 4 \\
    \hline
  \end{tabular}
  =
  \begin{center}
  \begin{tabular}{|c|c|}
    \hline
    $U^p_{(1,1)}$ & $U^p_{(1,2)}$  \\
    \hline
    $U^p_{(2,1)}$ & $U^p_{(2,2)}$  \\
    \hline
    $U^p_{(3,1)}$ & $U^p_{(3,2)}$  \\
    \hline
    $U^p_{(4,1)}$ & $U^p_{(4,2)}$  \\
    \hline
  \end{tabular}
  *
  \begin{tabular}{|c|c|}
    \hline
    $V^p_{(1)}$ & 0  \\
    \hline
    0 & $V^p_{(2)}$  \\
    \hline
  \end{tabular}
  *
  \begin{tabular}{|c|c|c|}
    \hline
    $I^p_{(1,1)}$ & $I^p_{(1,2)}$ & $I^p_{(1,3)}$  \\
    \hline
    $I^p_{(2,1)}$ & $I^p_{(2,2)}$ & $I^p_{(2,3)}$  \\
    \hline
  \end{tabular}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{SVD}
  Avantages : \\
  On choisit le nombre de valeurs singulières de notre transformation (PCA). \\
  Filtrage collaboratif user-based $\Rightarrow U^p$\\
  Filtrage collaboratif item-based $\Rightarrow I^p$
\end{frame}

\begin{frame}
  \frametitle{SVD}
  La SVD est extrèmement coûteuse sur des grandes matrices :
  \begin{center}
    $O(min(m*n^2,m^2*n))$
  \end{center}
  Heureusement des algorithmes approchés existent. Ces approches tirent parti du fait que les matrices sont généralement sparses et que l'on ne s'intéresse qu'a un nombre limité de valeurs singulières. \\
  Par exemple, on peut calculer les 20 premières valeurs singulières d'une matrice 100k x 100k avec 1M valeurs non-nulles en moins d'une seconde (redsvd).
\end{frame}

\begin{frame}
  \frametitle{Embeddings}
  Utilisation d'Embeddings sur les utilisateurs et les items afin de pouvoir exprimer la matrice des ratings ainsi : \\
  $M = U^{embed}*I^{embed}$ \\
  \newline
  Pour Faire une recommandation :\\
  $argmax(u_{query}*I^t)$
  
\end{frame}

\begin{frame}
  \frametitle{Recommandation par le contenu}
  Jusqu'à présent, la nature des items était sans importance.\\
  Que les items soient des livres ou des voitures, l'algorithme ne faisait aucune différence. \\
  On peut utiliser les détails textuels, les images (, etc...) sur les items afin d'améliorer les recommandations. (Embeddings, Catégorisation des items)
\end{frame}
