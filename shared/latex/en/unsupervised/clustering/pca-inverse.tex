\begin{frame}{PCA clustering}
  (Remember)

  \begin{itemize}
    \item Calculation of the covariance matrix (respectively correlation):
      \[
      \frac{1}{N} \times \overline{X^T} \times \overline{X}
      \quad
      ( \frac{1}{N} \times \widetilde{X^T} \times \widetilde{X} )
      \]
    \item Calculation of the matrix eigenvectors: they are the linear combinations of the new columns
    \item Sorting the vectors by decreasing eigenvalue
    \item Dimensionality reduction: we keep only the first $k$ eigenvectors
  \end{itemize}
\end{frame}

\begin{frame}{PCA clustering}
  We can use the transpose of our matrix: our samples become features and our features become samples.

  Eigenvectors can then be considered as centroids.
\end{frame}
