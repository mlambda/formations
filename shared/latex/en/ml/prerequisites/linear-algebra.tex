\begin{frame}{Goal}

  \begin{itemize}[<+->]
  \item describe simple transformations on a dataset with the correct mathematical tools
  \item understand the pros and cons of those simple transformations
  \end{itemize}
\end{frame}

\begin{frame}{Linear transformation}

  \begin{itemize}
  \item linear algebra means we limit ourselves to weighted sums of the input
  \item good news: it's a huge part of machine learning operations
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Describing data — sample}
  \begin{columns}
    \begin{column}{0.5\textwidth}
      Python :
      \begin{minted}{python}
sample = (1, 3)
      \end{minted}
    \end{column}
    \begin{column}{0.5\textwidth}
      Linear algebra \\[.3cm]

      \( \mathbf{s} = \begin{bmatrix}
        1 \\
        3 \\
      \end{bmatrix}
      \)
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}[fragile]{Describing data — dataset}
  \begin{columns}
    \begin{column}{0.5\textwidth}
      Python
      \begin{minted}{python}
data = [(1, 3),
        (2, 2),
        (4, 2)]
      \end{minted}
    \end{column}
    \begin{column}{0.5\textwidth}
      Linear algebra\\[.3cm]

      \(
      \mathbf{D} = \begin{bmatrix}
        1 & 2 & 4 \\
        3 & 2 & 2 \\
      \end{bmatrix}
      \)
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}[fragile]{Describing linear transformations}
  \begin{columns}
    \begin{column}{0.5\textwidth}
      Python
\begin{minted}{python}
def weights(x, y):
    return x * 2 + y / 2
\end{minted}
    \end{column}
    \begin{column}{0.5\textwidth}
      Linear algebra\\[.3cm]

      \(
      \mathbf{w} = \begin{bmatrix}
        2 & \frac{1}{2} \\
      \end{bmatrix}
      \)
    \end{column}
  \end{columns}
  \vfill
  Linear transformation = weighted sum.
\end{frame}

\begin{frame}{Applying linear transformations to a dataset}
  Matrix multiplication:

  \V{["img/linear-algebra-en", "tw", 0.7] | image}

  Mnemonic: pouring the columns (the dataset samples) into the lines (linear transformations).
\end{frame}

\begin{frame}{Applying linear transformations to a dataset}

  \V{["img/linear-algebra-run-en", "tw", 0.7] | image}

  Mnemonic: pouring the columns (the dataset samples) into the lines (linear transformations).
\end{frame}

\begin{frame}[fragile]{Applying a linear transformation to a sample}
  \begin{columns}
    \begin{column}{0.5\textwidth}
      Python
\begin{minted}{python}
data = (1, 3)

def weights(x, y):
    return 2 * x + y / 2

res = weights(*data)
\end{minted}
    \end{column}
    \begin{column}{0.5\textwidth}
      Linear algebra\\[.3cm]

      \(
      \begin{aligned}
        f & = \begin{bmatrix}
          2 & \frac{1}{2} \\
        \end{bmatrix}
        \begin{bmatrix}
          1 \\
          3 \\
        \end{bmatrix} \\
        & = 2 \times 1 + \frac{1}{2} \times 3
      \end{aligned}
      \)
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}[fragile]{Applying a linear transformation to a dataset}
  \begin{columns}
    \begin{column}{0.5\textwidth}
      Python
\begin{minted}{python}
data = [(1, 3),
        (2, 2),
        (4, 2)]

def f(x, y):
    return x * 2 + y / 2

res = [f(x, y)
       for x, y
       in data]
\end{minted}
    \end{column}
    \begin{column}{0.5\textwidth}
      Linear algebra\\[.3cm]

      \(
      \begin{aligned}
        \text{res} &
        = \begin{bmatrix}
          {\only<2>{\color{blue}}
            \only<3>{\color{green}}
            \only<4>{\color{red}}2} &
          {\only<2>{\color{blue}}
            \only<3>{\color{green}}
            \only<4>{\color{red}}\frac{1}{2}} \\
        \end{bmatrix}
        \begin{bmatrix}
          {\only<2>{\color{blue}}1} & {\only<3>{\color{green}}2} & {\only<4>{\color{red}}4} \\
          {\only<2>{\color{blue}}3} & {\only<3>{\color{green}}2} & {\only<4>{\color{red}}2} \\
        \end{bmatrix} \\
        \onslide<2->{
          & = \begin{bmatrix}
            \onslide<2->{\only<2>{\color{blue}}3,5} &
            \onslide<3->{\only<3>{\color{green}}5} &
            \onslide<4->{\only<4>{\color{red}}9}
            \\
          \end{bmatrix} \\
        }
      \end{aligned}
      \)
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}[fragile]{Applying several linear transformations to a dataset}
  \begin{columns}
    \begin{column}{0.5\textwidth}
      Python
\begin{minted}{python}
data = [(1, 3), (2, 2),
        (4, 2)]

def f(x, y):
    return x * 2 + y / 2

def g(x, y):
    return x / 2 + y * 2

res = [[t(x, y) for x, y
                in data]
       for t in [f, g]]
\end{minted}
    \end{column}
    \begin{column}{0.5\textwidth}
      Linear algebra\\[.3cm]

      \(
      \begin{aligned}
        \text{res} & = \begin{bmatrix}
            {\only<2>{\color{blue}}
              \only<3>{\color{green}}
              \only<4>{\color{red}}2} &
            {\only<2>{\color{blue}}
              \only<3>{\color{green}}
              \only<4>{\color{red}}\frac{1}{2}} \\
            {\only<5>{\color{blue}}
              \only<6>{\color{green}}
              \only<7>{\color{red}}\frac{1}{2}} &
            {\only<5>{\color{blue}}
              \only<6>{\color{green}}
              \only<7>{\color{red}}2} \\
          \end{bmatrix}
          \begin{bmatrix}
            {\only<2,5>{\color{blue}}1} & {\only<3,6>{\color{green}}2} & {\only<4,7>{\color{red}}4} \\
            {\only<2,5>{\color{blue}}3} & {\only<3,6>{\color{green}}2} & {\only<4,7>{\color{red}}2} \\
          \end{bmatrix} \\
        \onslide<2->{
          & = \begin{bmatrix}
            \onslide<2->{\only<2>{\color{blue}}3,5} &
            \onslide<3->{\only<3>{\color{green}}5} &
            \onslide<4->{\only<4>{\color{red}}9}
            \\
            \onslide<5->{\only<5>{\color{blue}}6,5} &
            \onslide<6->{\only<6>{\color{green}}5} &
            \onslide<7->{\only<7>{\color{red}}6}
            \\
          \end{bmatrix} \\
        }
      \end{aligned}
      \)
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{Mnemonic}

  \V{["img/linear-algebra-en", "tw", 1] | image}
\end{frame}

\begin{frame}{Mnemonic}

  \V{["img/linear-algebra-run-en", "th", 0.8] | image}
\end{frame}

\begin{frame}{Exercise}
  \[
    \begin{bmatrix}
      1 & 2 \\
      2 & 0 \\
    \end{bmatrix}
    \begin{bmatrix}
      0 & 0 & 1 & 1 \\
      0 & 1 & 1 & 0 \\
    \end{bmatrix}
    = \green{?}
  \]
\end{frame}

\begin{frame}{Linear transformation example}

  \V{["img/linear-transformation", "tw", 0.5] | image}
  \[
    \begin{aligned}
      \text{Blue} & = \text{Transformation} \times \text{Red} \\
      & = \begin{bmatrix}
        1 & 2 \\
        2 & 0 \\
      \end{bmatrix}
      \begin{bmatrix}
        0 & 0 & 1 & 1 \\
        0 & 1 & 1 & 0 \\
      \end{bmatrix} \\
      & = \begin{bmatrix}
        0 & 2 & 3 & 1 \\
        0 & 0 & 2 & 2 \\
      \end{bmatrix}
    \end{aligned}
  \]
\end{frame}

\begin{frame}{Eigenvector}

  \V{["img/linear-transformation", "tw", 0.5] | image}

  Vector starting from the origin that keeps its direction after the transformation.

  \alert{Can you spot one?}
  \visible<+(1)->{$\begin{bmatrix}1 \\0\end{bmatrix}$ for example.}
\end{frame}

\begin{frame}{Eigenvalue}

  \V{["img/linear-transformation", "tw", 0.5] | image}

  Factor by which an eigenvector is stretched.

  \alert{What is the eigenvalue of $\begin{bmatrix}1 \\ 0\end{bmatrix}$?}
  \visible<+(1)>{$2$.}
\end{frame}
