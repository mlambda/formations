\begin{frame}{Linearly separable data}
  \V{["img/separable-problem-linear-nzmog", "tw", 0.8, "en"] | image}
\end{frame}

\begin{frame}{Wrong solution -- Training data}
  \V{["img/separable-problem-linear-solution-nzmog", "tw", 0.8, "en"] | image}
\end{frame}

\begin{frame}{Wrong solution -- Nex data}
  \V{["img/separable-problem-linear-solution-bad-nzmog", "tw", 0.8, "en"] | image}
\end{frame}

\begin{frame}{SVM solution}
  \V{["img/svm-schema-nzmog", "tw", 0.8, "en"] | image}
\end{frame}

\begin{frame}{Non-linearly separable data}
  \V{["plt/separable-problem-nonlinear-solution", "th", 0.75, "en"] | image}
\end{frame}

\begin{frame}{Kernel transformation (here polynomiale)}
  \V{["plt/separable-problem-nonlinear-kernelsvm", "th", 0.75, "en"] | image}
\end{frame}

\begin{frame}{Strategies for multi-class classification}
  For a $k$ class problem:

  \begin{description}
    \item[One versus all] $k$ models. Best score aggregation.
    \item[One versus one] $\frac{k(k - 1)}{2}$ models. Majority vote.
  \end{description}
\end{frame}
