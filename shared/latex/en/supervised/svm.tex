\begin{frame}{Linearly separable data}
  \V{"img/separable-problem-linear-nzmog" | image("tw", 0.8, "en")}
\end{frame}

\begin{frame}{Wrong solution -- Training data}
  \V{"img/separable-problem-linear-solution-nzmog" | image("tw", 0.8, "en")}
\end{frame}

\begin{frame}{Wrong solution -- Nex data}
  \V{"img/separable-problem-linear-solution-bad-nzmog" | image("tw", 0.8, "en")}
\end{frame}

\begin{frame}{SVM solution}
  \V{"img/svm-schema-nzmog-en" | image("tw", 0.8)}
\end{frame}

\begin{frame}{Non-linearly separable data}
  \V{"plt/separable-problem-nonlinear-solution" | image("th", 0.75, "en")}
\end{frame}

\begin{frame}{Kernel transformation (here polynomiale)}
  \V{"plt/separable-problem-nonlinear-kernelsvm" | image("th", 0.75, "en")}
\end{frame}

\begin{frame}{Strategies for multi-class classification}
  For a $k$ class problem:

  \begin{description}
    \item[One versus all] $k$ models. Best score aggregation.
    \item[One versus one] $\frac{k(k - 1)}{2}$ models. Majority vote.
  \end{description}
\end{frame}
