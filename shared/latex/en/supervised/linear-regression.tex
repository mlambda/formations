\begin{frame}{Problem definition}
  Let $\{( x_i , y_i)\} \subset \mathbb{R}^2$ be a dataset where $x$ is the input variable and $y$ is the output variable.

  Find $f$ defined as $f(x_i) = ax_i + b = \hat{y_i}$ such that

  \[
    \min_{f} \sum_i \text{error}(\hat{y_i}, y_i)
  \]

  where $\text{error}$ is a function that measures the difference between the true $y_i$ and the prediction $\hat{y_i}$.
\end{frame}

\begin{frame}{Visualization}
  \V{["regression-nzmog", "th", 0.7, "en"] | image}
\end{frame}
