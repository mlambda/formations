\begin{frame}
  \frametitle{Support Vector Machine}
  \imgtw{separable-problem-linear}{0.8}
\end{frame}

\begin{frame}
  \frametitle{Support Vector Machine}
  \imgtw{separable-problem-linear-solution}{0.8}
\end{frame}

\begin{frame}
  \frametitle{Support Vector Machine}
  \imgtw{separable-problem-linear-solution-bad}{0.8}
\end{frame}

\begin{frame}
  \frametitle{Support Vector Machine}
  \imgtw{separable-problem-linear-svm}{0.8}
\end{frame}

\begin{frame}
  \frametitle{Support Vector Machine}
  \imgtw{svm-schema}{0.9}
\end{frame}

\begin{frame}
  \frametitle{Support Vector Machine}
  \imgtw{separable-problem-nonlinear}{0.8}
\end{frame}

\begin{frame}
  \frametitle{Support Vector Machine}
  \imgtw{separable-problem-nonlinear-solution}{0.8}
\end{frame}

\begin{frame}
  \frametitle{Support Vector Machine}
  \imgtw{separable-problem-nonlinear-kernelsvm}{0.9}
\end{frame}

\begin{frame}
  \frametitle{Support Vector Machine}
  Généralisation à un problème de régression logistique à $K>2$ classes :
  \begin{itemize}
  \item One Vs All : K modèles. Agréagation par meilleur score.
  \item One Vs One : $\frac{K(K-1)}{2}$ modèles. Vote majoritaire.
  \end{itemize}
\end{frame}
