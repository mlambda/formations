\begin{frame}{Introduction}
  Modèle de classification ou regréssion qui classe un input dans une
  de ses feuilles pour rendre sa prédiction :
  \V{["tikz/tree/decision", "th", 0.6] | image}
\end{frame}

\begin{frame}{Avantages}
  Les arbres de décision
  \begin{itemize}[<+->]
  \item gèrent les inputs numériques comme catégoriels
  \item ne nécessitent pas que la variable d'output soit normalement
    distribuée (regression linéaire)
  \item sont interprétables
  \item sont très rapides durant l'inférence
  \item ne nécessitent pas de normalisation des données
  \item leur apprentissage est hautement parallèlisable
  \end{itemize}
  \onslide<+->{→ Couteau-suisse du machine learning tabulaire.}
\end{frame}

\begin{frame}{Désavantages}
  \begin{itemize}[<+->]
  \item peuvent overfit les données, mais l'ensembling résoud ce
    problème
  \item sont sensibles aux déséquilibres de classe
  \end{itemize}
  \onslide<+->{→ Si les classes ne sont pas équilibrées, peut-être les
    resampler.}
\end{frame}

\begin{frame}{Arbres de classification}
  \V{["tikz/tree/decision", "tw", 1] | image}
\end{frame}

\begin{frame}{Arbres de régression}
  \V{["tikz/tree/regression", "tw", 1] | image}
\end{frame}

\begin{frame}{Apprendre un arbre de décision}
  Approche \og top-down\fg, procédure récursive :
  \begin{itemize}[<+->]
  \item créer un nœud de départ qui contient toutes les instances du
    training set
  \item tant qu'il reste des nœuds non-traités :
    \begin{itemize}
    \item choisir un nœud non traité
    \item si le nœud remplit des conditions de feuille finale, ne rien
      faire
    \item sinon, créer deux branches à partir du nœud non traité
      pour répartir les instances dans deux nouveaux nœuds
    \end{itemize}
  \end{itemize}
  \onslide<+->{Conditions de feuilles finales : contient $n_{min}$
    éléments, est déjà à profondeur $p_{max}$, splitterait sans
    décroître assez l'entropie…}
\end{frame}

\begin{frame}{Décision rendue}
  En fonction de la tâche, une fois arrivé dans la feuille de fin :
  \begin{description}
  \item[Classification] classe majoritaire
  \item[Régression] moyenne des valeurs cibles
  \end{description}
\end{frame}

\begin{frame}{Splits possibles}
  Splits possibles d'une feature donnée :
  \begin{description}
  \item[Catégorielle] chaque catégorie vs le reste
  \item[Ordinale/Continue] milieu de chaque valeur ou
    quantiles
  \end{description}
\end{frame}
