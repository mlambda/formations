{"titre": "Deep Learning \u2013 Expertise", "competences": ["Cr\u00e9er et entra\u00eener un mod\u00e8le de r\u00e9seaux de neurones avec Keraset Tensorflow", "Utiliser le deep learning pour tout type d\u2019apprentissage(Classification, pr\u00e9diction, non supervis\u00e9, renforcement)", "Traiter automatiquement des donn\u00e9es tabulaires", "Traiter automatiquement des donn\u00e9es images", "Traiter automatiquement des donn\u00e9es textuelles ou s\u00e9quentielles", "Proposer une structure de mod\u00e8le moderne \u00e0 un probl\u00e8me particulier", "Impl\u00e9menter les m\u00e9thodes les plus r\u00e9centes pour tout typede probl\u00e8me d\u2019apprentissage automatique"], "public": "Ing\u00e9nieurs et data scientists souhaitant une vision compl\u00e8te  du domaine du deep learning et des m\u00e9thodes \u00e9tat de l\u2019art.", "prerequis": "Une connaissance de base \u00e0 Python est requise, ainsi qu\u2019une connaissance  des concepts clefs du machine learning et des r\u00e9seaux de neurones.", "nb_jours": "> 4 jours", "plan": {"partie-1": {"nom": "Concepts fondamentaux des r\u00e9seaux de neurones : ", "contenu": ["Lien avec la r\u00e9gression lin\u00e9aire", "Structure g\u00e9n\u00e9rale des r\u00e9seaux de neurones", "Rupture de la lin\u00e9arit\u00e9 : les fonctions d\u2019activations", "Convergence des mod\u00e8les et choix des optimiseurs du taux d\u2019apprentissage", "Probl\u00e8mes li\u00e9s \u00e0 la disparition ou l\u2019explosion de gradient", "Impact et choix d\u2019un batch", "Techniques de r\u00e9gularisation : R\u00e9gularisation L1/L2, bruitage,dropout", "Recherche des hyperparam\u00e8tres", "Probl\u00e8mes d\u2019interpr\u00e9tabilit\u00e9", "La librairie Keras pour impl\u00e9menter des r\u00e9seaux de neuronesprofonds en python", "Impl\u00e9mentation avanc\u00e9e avec le GradientTape"], "pratique": "* Mise en place d\u2019un r\u00e9seau de neurones sans code sur des donn\u00e9es   simples. Les stagiaires doivent choisir le meilleur ensemble   d\u2019hyperparam\u00e8tres pour apprendre au mieux un jeu de donn\u00e9es   sans surapprentissage et en optimisant le temps de convergence   du mod\u00e8le. * Impl\u00e9mentation d\u2019un r\u00e9seau de neurones via Keras sur un probl\u00e8me   de classification multiclasse. Les stagiaires devront utiliser   les concepts de s\u00e9paration de jeux de donn\u00e9es et d\u2019\u00e9valuation   introduits en partie 2 et d\u00e9ployer un protocole de recherche   d\u2019hyperparam\u00e8tres * Impl\u00e9mentation de couches et de mod\u00e8les personnalis\u00e9s en   utilisant le GradientTape", "objectifs": ["Concevoir et impl\u00e9menter des mod\u00e8les de r\u00e9seaux de neuronessur des donn\u00e9es tabulaires en Keras pour la r\u00e9gression et laclassification", "\u00c9valuer la performance de leurs mod\u00e8les et adapter les hyperparam\u00e8trespour am\u00e9liorer l\u2019apprentissage", "Identifier les probl\u00e8mes d\u2019apprentissage tels que le surapprentissageou le manque de donn\u00e9es et trouver les moyens de les r\u00e9soudre", "Reproduire un mod\u00e8le \u00e9tat de l\u2019art non impl\u00e9ment\u00e9 dans la librairieKeras"], "duree": "1 journ\u00e9e {text:soft-page-break}"}, "partie-2": {"nom": "R\u00e9seaux de neurones \u00e0 convolutions : ", "contenu": ["Traitement de l\u2019image avec de r\u00e9seau de neurones : les r\u00e9seauxde neurones \u00e0 convolutions", "Principe des convolutions", "Autres m\u00e9canismes des r\u00e9seaux \u00e0 convolutions : pooling, paddinget strides", "Architectures modernes de r\u00e9seaux \u00e0 convolutions : VGG, EfficientNet,DenseNet, etc.", "Techniques avanc\u00e9es utilisant r\u00e9seaux \u00e0 convolutions : segmentation,d\u00e9tection d\u2019objet, super-\u00e9chantillonnage, d\u00e9tection d\u2019anomalies", "Impl\u00e9mentation des r\u00e9seaux \u00e0 convolutions dans Keras"], "pratique": "* Impl\u00e9mentation d\u2019un r\u00e9seau de neurones \u00e0 convolutions pour   la classification d\u2019un jeu de donn\u00e9es de paysage * Impl\u00e9mentation d\u2019un mod\u00e8le de d\u00e9tections d\u2019anomalies semi-supervis\u00e9", "objectifs": ["Impl\u00e9menter un mod\u00e8le de r\u00e9seaux de neurones pour le traitementautomatique d\u2019images", "D\u00e9finir les mod\u00e8les pertinents \u00e0 utiliser en fonction deslimitations techniques et des objectifs \u00e0 r\u00e9aliser", "Utiliser le transfert d\u2019apprentissage pour am\u00e9liorer lesmod\u00e8les de traitement automatique d\u2019images", "Impl\u00e9menter des mod\u00e8les complexes de r\u00e9seaux \u00e0 convolutionspour des taches sp\u00e9cifiques"], "duree": "1 journ\u00e9e"}, "partie-3": {"nom": "R\u00e9seaux R\u00e9currents : ", "contenu": ["R\u00e9seaux de neurones r\u00e9currents", "LSTM : Long Short Term Memory", "GRU : Gated Recurrent Units", "Traitement automatique du texte et de la langue", "Traitement des flux vid\u00e9os : association avec les r\u00e9seauxconvolutionnels", "Limitations des r\u00e9seaux r\u00e9currents et probl\u00e8mes de convergence"], "pratique": "* Cr\u00e9ation d\u2019un mod\u00e8le de reconnaissance d\u2019auteurs automatique * Cr\u00e9ation d\u2019un mod\u00e8le de solveur arithm\u00e9tique sur donn\u00e9es   textuelles (Traducteur texte \u2192 maths) * G\u00e9n\u00e9ration automatique de texte", "objectifs": ["Traiter automatiquement des donn\u00e9es s\u00e9quentielles", "Classifier des donn\u00e9es s\u00e9quentielles", "G\u00e9n\u00e9rer des pr\u00e9dictions ou des s\u00e9quences futures", "Traiter des donn\u00e9es vid\u00e9os"], "duree": "1 journ\u00e9e"}, "partie-4": {"nom": "G\u00e9n\u00e9ration automatique : Auto-encodeurs et GAN : ", "contenu": ["La r\u00e9duction de dimensions par les r\u00e9seaux de neurones", "La structure encodeur-d\u00e9codeur des auto-encodeurs", "Concept d\u2019embedding", "Notions d\u2019espace latent", "R\u00e9seaux adversaire : Generative Adversarial Networks", "Probl\u00e8me de convergence et mod\u00e8les avanc\u00e9s ; WassersteinGAN"], "pratique": "* Impl\u00e9mentation d\u2019un auto-encodeur en keras et visualisation   de l\u2019espace latent", "objectifs": ["Identifier les mod\u00e8les avanc\u00e9s bas\u00e9s sur des structures encodeur-d\u00e9codeur", "Concevoir et impl\u00e9menter des algorithmes des auto-encodeurssur des t\u00e2ches d\u2019apprentissage non supervis\u00e9s", "Int\u00e9grer des mod\u00e8les auto-encodeurs \u00e0 des mod\u00e8les existantsde traitements supervis\u00e9s pour r\u00e9duire la dimensionnalit\u00e9d\u2019un jeu de donn\u00e9es", "Produire des mod\u00e8les g\u00e9n\u00e9ratifs de donn\u00e9es"], "duree": "1 demi-journ\u00e9e"}, "partie-5": {"nom": "Apprentissage par renforcement : ", "contenu": ["Concepts du reinforcement learning", "Approximation automatique de la fonction d\u2019\u00e9tat", "Deep Q Learning", "Applications"], "pratique": "* Utilisation d\u2019un mod\u00e8le de renforcement simple pour apprendre   une table de Q-learning", "objectifs": ["D\u00e9velopper un mod\u00e8le de renforcement", "Estimer le temps, le volume de donn\u00e9es et les ressources n\u00e9cessairespour entrainer un mod\u00e8le d\u2019apprentissage par renforcement."], "duree": "1 demi-journ\u00e9e"}}}